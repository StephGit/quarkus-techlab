[{"body":"Task 1.1: Quarkus \u0026ldquo;Quarkus is a Kubernetes Native Java stack tailored for GraalVM \u0026amp; OpenJDK HotSpot, crafted from the best of breed Java libraries and standards. Also focused on developer experience, making things just work with little to no configuration and allowing to do live coding.\u0026rdquo; - quarkus.io\nIn short, Quarkus brings a framework built upon JakartaEE standards to build microservices in the Java environment. Per default Quarkus comes with full CDI integration, RESTeasy-JAX-RS, dev mode and many more features.\nQuarkus provides a list of extensions and frameworks which can be included into your Quarkus project. Extensions (Hibernate ORM, Liquibase, Flyway, SmallRye Reactive Messageing, and many others) are minified and customized to work with the minimal resource consuming framework.\nDue to the optimization of extensions and the framework itself, Quarkus can be used to create very resource friendly and efficient microservices. For example a normal REST API created in Quarkus takes around 12MB Memory RSS when built and compiled with the GraalVM as a native Image, Compiled and run by the JVM the application takes about 73MB Memory RSS which is still pretty slim compared to a standard Java stack which takes about 136MB Memory RSS.\nAlso the startup times benefit massively from the minified dependencies and framework. A REST API starts when built as a native image in about 0.016 seconds. When run in a normal JVM the application starts up in about 0.943 seconds. A traditional Java stack uses about 9.5 seconds to start up.\nDue to the low memory consumption and fast startup times, Quarkus applications are very well suited for the usage in a cloud native environment. It makes the application fast and dynamically scalable.\nQuarkus is open source and developed under the Apache License version 2.0. The entire source code is hosted on Github and has an active community.\n","excerpt":"Task 1.1: Quarkus \u0026ldquo;Quarkus is a Kubernetes Native Java stack tailored for GraalVM \u0026amp; …","ref":"/quarkus-techlab/docs/01.0/","title":"1. Introduction to Quarkus"},{"body":"    Slides Get the slides for this lab\nRead more …\n    ","excerpt":"    Slides Get the slides for this lab\nRead more …\n    ","ref":"/quarkus-techlab/slides/","title":"Slides"},{"body":"","excerpt":"","ref":"/quarkus-techlab/docs/02.0/","title":"2. Implementing REST services in Quarkus"},{"body":"","excerpt":"","ref":"/quarkus-techlab/docs/03.0/","title":"3. Build Quarkus applications"},{"body":"As mentioned before the Quarkus framework is tailored for the cloud environment. Now we will test and see how easy it is to run our Quarkus applications on OpenShift 4. You will need the OpenShift CLI binary oc for the next few steps. If you don\u0026rsquo;t have it already installed, log into the OpenShift cluster (console.ocp.aws.puzzle.ch) and download the binary provided in the help tab ? in the header bar under Command Line Tools.\n","excerpt":"As mentioned before the Quarkus framework is tailored for the cloud environment. Now we will test …","ref":"/quarkus-techlab/docs/04.0/","title":"4. OpenShift / Kubernetes"},{"body":"Tekton is a Kubernetes-native, continuous integration and delivery (CI/CD) framework that enables you to create containerized, composable, and configurable workloads declaratively through CRDs. In this section we are going to define and create pipelines using Tekton to apply our defined manifests, build and deploy our images.\n5.1: Pipelines With OpenShift 4 pipelines come in as a tech-preview feature. They represent a cloud-native CI/CD solution based on Kubernetes resources. Under the hood it uses Tekton building blocks to automate deployment by abstracting away the underlaying implementation details. Pipelines are a serverless system which runs pipelines with all required dependencies isolated in containers.\nLet\u0026rsquo;s dive in and look at the resources.\nOpenShift pipelines provide a set of standard Custom Resource Definitions (CRDs) that act as the building blocks for your pipeline the important concepts and resources are:\n5.1.1: Task A Task is the smallest configurable unit in a Pipeline. It is essentially a function of inputs and outputs that form the Pipeline build. It can run individually or as a part of a Pipeline. A Pipeline includes one or more Tasks, where each Task consists of one or more steps. Steps are a series of commands that are sequentially executed by the Task.\n5.1.2: Pipeline A Pipeline consists of a series of Tasks that are executed to construct complex workflows that automate the build, deployment, and delivery of applications. It is a collection of PipelineResources, parameters, and one or more Tasks. A Pipeline interacts with the outside world by using PipelineResources, which are added to Tasks as inputs and outputs.\n5.1.3: PipelineRun A PipelineRun is the running instance of a Pipeline. A PipelineRun initiates a Pipeline and manages the creation of a TaskRun for each Task being executed in the Pipeline.\n5.1.4: TaskRun A TaskRun is automatically created by a PipelineRun for each Task in a Pipeline. It is the result of running an instance of a Task in a Pipeline. It can also be manually created if a Task runs outside of a Pipeline.\n5.1.5: PipelineResource A PipelineResource is an object that is used as an input and output for Pipeline Tasks. For example, if an input is a Git repository and an output is a container image built from that Git repository, these are both classified as PipelineResources. PipelineResources currently support Git resources, Image resources, Cluster resources, Storage Resources and CloudEvent resources.\n5.1.6: Trigger A Trigger captures an external event, such as a Git pull request and processes the event payload to extract key pieces of information. This extracted information is then mapped to a set of predefined parameters, which trigger a series of tasks that may involve creation and deployment of Kubernetes resources. You can use Triggers along with Pipelines to create full-fledged CI/CD systems where the execution is defined entirely through Kubernetes resources.\n5.1.7: Condition A Condition refers to a validation or check, which is executed before a Task is run in your Pipeline. Conditions are like if statements which perform logical tests, with a return value of True or False. A Task is executed if all Conditions return True, but if any of the Conditions fail, the Task and all subsequent Tasks are skipped. You can use Conditions in your Pipeline to create complex workflows covering multiple scenarios.\nStatic definition of a Pipeline\nRuntime view of a Pipeline showing mapping to pods and containers\n","excerpt":"Tekton is a Kubernetes-native, continuous integration and delivery (CI/CD) framework that enables …","ref":"/quarkus-techlab/docs/05.0/","title":"5. Automation with CI/CD pipelines"},{"body":"Modern web applications running a microservice architecture need information to flow through multiple microservices. We have already seen one way of communication between two microservices, we exposed a REST interface on one application and consumed it from another. Communication through REST is very easy to implement and understand but it has also it\u0026rsquo;s downsides. For example what happens when our called microservice is not available. The REST call will just return a time-out and every application has to handle it\u0026rsquo;s fallback by itself. Here the concept of Messaging comes in handy. Messaging allows our application to be loosely coupled by communicating asynchronously. It transfers the responsibility of handling the information flow between single nodes of your application to the message broker.\n6.1: Concepts To understand what we are talking about we have to establish some vocabulary and define§ core concepts.\n6.1.1: Message Broker A message broker is software that enables applications, systems, and services to communicate with each other and exchange information. The message broker does this by translating messages between formal messaging protocols. This allows interdependent services to “talk” with one another directly, even if they were written in different languages or implemented on different platforms.\nMessage brokers are software modules within messaging middleware or message-oriented middleware (MOM) solutions. This type of middleware provides developers with a standardized means of handling the flow of data between an application’s components so that they can focus on its core logic. It can serve as a distributed communications layer that allows applications spanning multiple platforms to communicate internally.\n6.1.2: Message A Message is an envelope around a payload. Your application is going to receive, process and send Messages. These Messages can be generated by your application, or are retrieved from a message broker. They can also be consumed by your application, or sent to a message broker.\n6.1.3: Channels Messaging applications transmit data through a Message Channel, a virtual pipe that connects a sender to a receiver. A newly installed messaging system doesn’t contain any channels; you must determine how your applications need to communicate and then create the channels to facilitate it.\n6.1.4: Queue Pattern A Queue is defined as a point-to-point Channel (Queue), where one of multiple producers produces a message which will be consumed by exactly one available consumer.\n6.1.5: Publish/Subscribe Pattern A Topic describes a broadcast Channel (Topic), a message will be consumed by all available consumers.\n6.1.6: Connectors Your application is interacting with messaging brokers or event backbone using connectors. A connector is a piece of code that connects to a broker and:\n subscribe / poll / receive messages from the broker and propagate them to the application send / write / dispatch messages provided by the application to the broker  To achieve this, connectors are configured to map incoming messages to a specific channel (consumed by the application) and to collect outgoing messages sent to a specific channel by the application. These collected messages are sent to the external broker.\n","excerpt":"Modern web applications running a microservice architecture need information to flow through …","ref":"/quarkus-techlab/docs/06.0/","title":"6. Messaging with ActiveMQ Artemis"},{"body":"7.1: The Reactive Manifesto \u0026ldquo;Today\u0026rsquo;s demands are simply not met by yesterday’s software architectures.\u0026rdquo; - The Reactive Manifesto\nOld fashioned applications - often built as monoliths - struggle to meet the requirements of todays workload dimensions. Applications should become scalable, robust and easy to maintain. Similar to the twelve-factor-app manifesto there is a Reactive Manifesto. It describes requirements to tackle problems for modern enterprise solutions.\nThe Reactive Manifesto defines that reactive systems are:\n* Responsive * Resilient * Elastic * Message Driven  We have already learned basics of messaging in a microservice architecture. Time to take a next step and make our messaging reactive. The approach we have seen in the chapter before is completely legitimate and there is nothing wrong with this approach.\n7.2: Reactive Messaging In the last chapter we learned about basic messaging concepts and how two microservices can communicate with a message broker. In reactive messaging we connect channels directly to components. Instead of having a Thread running manually, we can annotate functions to bind them to events sent in a specific channel or data stream. This makes our code more readable and act in a reactive manner. Let\u0026rsquo;s look at an example:\n```java /* [...] */ @Incoming(\u0026quot;data-inbound-reactive\u0026quot;) @Outgoing(\u0026quot;data-outbound-reactive\u0026quot;) public String streamProcess(String value) { return value.toUpperCase(); } /* [...] */ ```  If you read this example it\u0026rsquo;s pretty clear what is happening. We are connecting with a Connector to a Channel (Queue or Topic) we call \u0026ldquo;data-inbound-reactive\u0026rdquo; and define it as the inbound connector for this method. On the other side we connect the outcome of this method to the \u0026ldquo;data-outbound-reactive\u0026rdquo; stream. Whenever the \u0026ldquo;data-inobund-reactive\u0026rdquo; stream sends an message we perform a transformation to uppercase and return the value into the \u0026ldquo;data-outbound-reactive\u0026rdquo; channel. Simple as that!\n7.2.1: Connectors Connector can:\n* retrieve messages from a remote broker (inbound) * send messages to a remove broker (outbound)  A connector can, of course, implement both directions.\nInbound connectors are responsible for:\n* Getting messages from the remote broker, * Creating a Reactive Messaging Message associated with the retrieved message. * Potentially associating technical metadata with the message. This includes unmarshalling the payload. * Associating a acknowledgement callback to acknowledge the incoming message when the Reactive Messaging message is acknowledged.  Important: Reactive matters! The first step should follow the reactive streams principle: uses non-blocking technology, respects downstream requests.\nOutbound connectors are responsible for:\n* Receiving Reactive Messaging Message and transform it into a structure understand by the remote broker. This includes marshalling the payload. * If the Message contains outbound metadata (metadata set during the processing to influence the outbound structure and routing), taking them into account. * Sending the message to the remote broker. * Acknowledging the Reactive Messaging Message when the broker has accepted / acknowledged the message.  7.2.2: Connectors Event Driven Architecture With this reactive messaging approach we can build our applications on an event driven approach. Some interaction or trigger emits an event to a certain channel. Subscribers of this channel consume the message and react based on the event received. This loosens the coupling in our application and lowers the cohesion between logically seperated components.\nIn an event driven approach everything that happens in our application gets triggered by an event. Events in the event-driven software model describe what happens within a software system. If we imagine our application as a set of logically ordered processes every task in these processes gets triggered by such an event and might emit another new event. This concept is very intuitive to apply because it is a very natural way of thinking about how everyday things and tasks work.\nSome typical patterns in event-driven architecture:\n7.2.3: Connectors Event notification In this approach, microservices emit events through channels to trigger behaviour or notify other components about the change of a state in the application. Notification events do not carry too much data and are very light weight. This results in a very effective and ressource friendly communication between the microservices.\n7.2.4: Connectors Event-carried state transfer Instead of only notifying about events this approach sends a payload as a message to another component containing every information needed to perform actions triggered by this event. This model comes very close to the typical RESTful approach and can be implemented very similar. Depending on the amount of data in the payload the network traffic might suffer under the amount of data transferred.\n7.2.4: Connectors Event-sourcing The goal of event-sourcing is to represent every change in a system\u0026rsquo;s state as an emitted event in chronological order. The event stream becomes the principle source of truth about the applications state. Changes in state, as sequences of events, are persisted in the event stream and can be \u0026lsquo;replayed\u0026rsquo;.\n","excerpt":"7.1: The Reactive Manifesto \u0026ldquo;Today\u0026rsquo;s demands are simply not met by yesterday’s software …","ref":"/quarkus-techlab/docs/07.0/","title":"7. Reactive messaging with Apache Kafka"},{"body":"8.1: Distributed Systems Applications consisting of several microservices reduce the cohesion and complexity of single parts of applications massively. By enforcing a single responsibility principle on the application\u0026rsquo;s architectural top layer the bottom-up vision brings a very clear image of what each part of a system does. On the other side the top-down vision of an application gets more complex. Handling errors across multiple microservices will become very frustrating and time consuming. This is very tracing comes in handy.\n8.2: Distributed Tracing with Opentracing The Opentracing project defines an API for distributed tracing in modern applications. It defines a certain terminology or semantic specification to avoid language-specific concepts.\n8.2.1: The OpenTracing Data Model Traces in Opentracing are defined implicitly by their Spans. In particular, a Trace can be thought of as a directed acyclic graph (DAG) of Spans, where the edges between Spans are called References.\nFor example, the following is an example Trace made up of 8 Spans:\nCausal relationships between Spans in a single Trace [Span A] ←←←(the root span) | +------+------+ | | [Span B] [Span C] ←←←(Span C is a `ChildOf` Span A) | | [Span D] +---+-------+ | | [Span E] [Span F] \u0026gt;\u0026gt;\u0026gt; [Span G] \u0026gt;\u0026gt;\u0026gt; [Span H] ↑ ↑ ↑ (Span G `FollowsFrom` Span F) Sometimes it\u0026rsquo;s easier to visualize Traces with a time axis as in the diagram below:\nTemporal relationships between Spans in a single Trace ––|–––––––|–––––––|–––––––|–––––––|–––––––|–––––––|–––––––|–\u0026gt; time [Span A···················································] [Span B··············································] [Span D··········································] [Span C········································] [Span E·······] [Span F··] [Span G··] [Span H··] Each Span encapsulates the following state:\n An operation name A start timestamp A finish timestamp A set of zero or more key:value Span Tags. The keys must be strings. The values may be strings, bools, or numeric types. A set of zero or more Span Logs, each of which is itself a key:value map paired with a timestamp. The keys must be strings, though the values may be of any type. Not all OpenTracing implementations must support every value type. A SpanContext (see below) References to zero or more causally-related Spans (via the SpanContext of those related Spans)  Each SpanContext encapsulates the following state:\n Any OpenTracing-implementation-dependent state (for example, trace and span ids) needed to refer to a distinct Span across a process boundary Baggage Items, which are just key:value pairs that cross process boundaries  8.2.2: The OpenTracing API There are three critical and inter-related types in the OpenTracing specification: Tracer, Span, and SpanContext. Below, we go through the behaviors of each type; roughly speaking, each behavior becomes a \u0026ldquo;method\u0026rdquo; in a typical programming language, though it may actually be a set of related sibling methods due to type overloading and so on.\n The Tracer interface creates Spans and understands how to Inject (serialize) and Extract (deserialize) them across process boundaries. Formally, it has the following capabilities. The Span allows us to retreive the Span\u0026rsquo;s SpanContext, Overwrite operations names, Finish the Span, Set Span Tags and log structured data. The SpanContext is more of a \u0026ldquo;concept\u0026rdquo; than a useful piece of functionality at the generic OpenTracing layer. That said, it is of critical importance to OpenTracing implementations and does present a thin API of its own. Most OpenTracing users only interact with SpanContext via references when starting new Spans, or when injecting/extracting a trace to/from some transport protocol.  ","excerpt":"8.1: Distributed Systems Applications consisting of several microservices reduce the cohesion and …","ref":"/quarkus-techlab/docs/08.0/","title":"8. Tracing"},{"body":"3.1.1 Build and Deploy our Quarkus microservices Talking about how nice Quarkus runs in the cloud environment is pretty neat, but doing is even better! So we take a step further and automate our builds and deployment with Jenkins and OpenShift. This part will consist of two sections, we will see how to implement build pipelines, which will trigger our OpenShift deployments and another which shows how to configure your OpenShift deployments.\nWe will see how we can build our applications like we used to as an JVM build, then we will try to build native executables with help of the GraalVM. Native executables will optimize the entire application in compile time and will afterwards not benefit from the classical Java runtime optimizations. Always keep in mind that Java applications due to it\u0026rsquo;s nature will get more performant the longer they run. With native executables we do have the exact opposite, applications will start up optimized and will run the fastest at the start. Be aware that a lot of classical Java features like reflection will not be available as you were used to when built natively. Reflections can be used, but the compiler needs to be aware of the reflection by annotating classes as @RegisterForReflection. You can read more about native build in the Documentation.\nTo build Docker images from your applications, Quarkus provides per default in each project Dockerfiles to support JVM and native builds. You don\u0026rsquo;t have to worry too much about how Dockerfiles need to be written, as they will be provided in this techlab.\n","excerpt":"3.1.1 Build and Deploy our Quarkus microservices Talking about how nice Quarkus runs in the cloud …","ref":"/quarkus-techlab/docs/03.0/build/","title":"3.1 Build Quarkus applications"},{"body":"3.2.1 To build a Quarkus application to be run with the JVM you can use the provided Dockerfile Dockerfile.jvm.\n~/data-producer ./mvnw clean package ~/data-consumer ./mvnw clean package ~/ docker build -f data-producer/src/main/docker/Dockerfile.jvm -t data-producer:latest data-producer/. ~/ docker build -f data-consumer/src/main/docker/Dockerfile.jvm -t data-consumer:latest data-consumer/.  The image will be produced and tagged as data-producer:latest / data-consumer:latest. You can test and run the built image locally with:\ndocker run --network host data-producer:latest docker run --network host data-consumer:latest When the applications are up and running you can test the API again:\ncurl http://localhost:8081/data You should get your desired response.\n","excerpt":"3.2.1 To build a Quarkus application to be run with the JVM you can use the provided Dockerfile …","ref":"/quarkus-techlab/docs/03.0/jvm-build/","title":"3.2 JVM Build"},{"body":"3.3.1 As the name says, native builds will run the Quarkus application as a native executable. The executable will get optimized and prepared in the ahead-of-time compilation process. As you would expect the compilation and build of a native executable takes a ridiculous amount of memory and time. Native executables are built by the GraalVM or the upstream community project Mandrel. If you want to read further about native executables in Quarkus head over to the official Documentation.\nFor now, we simply want to build native images to be fast as lightning!\nThere are multiple ways to build native images. One possibility is to install the GraalVM and use Maven locally with ./mvnw package -Pnative then use the Dockerfile.native to create your image. The lazy way is simpler. We create a multistage Dockerfile to do both steps in our docker build process.\n# Dockerfile.multistage## Stage 1 : build with maven builder image with native capabilitiesFROMquay.io/quarkus/centos-quarkus-maven:20.1.0-java11 AS buildCOPY pom.xml /usr/src/app/RUN mvn -f /usr/src/app/pom.xml -B de.qaware.maven:go-offline-maven-plugin:1.2.5:resolve-dependenciesCOPY src /usr/src/app/srcUSERrootRUN chown -R quarkus /usr/src/appUSERquarkusRUN mvn -f /usr/src/app/pom.xml -Pnative clean package## Stage 2 : create the docker final imageFROMregistry.access.redhat.com/ubi8/ubi-minimalWORKDIR/work/COPY --from=build /usr/src/app/target/*-runner /work/application# set up permissions for user `1001`RUN chmod 775 /work /work/application \\  \u0026amp;\u0026amp; chown -R 1001 /work \\  \u0026amp;\u0026amp; chmod -R \u0026#34;g+rwX\u0026#34; /work \\  \u0026amp;\u0026amp; chown -R 1001:root /workEXPOSE8080USER1001CMD [\u0026#34;./application\u0026#34;, \u0026#34;-Dquarkus.http.host=0.0.0.0\u0026#34;]Now you can create your own native executable with:\n~/data-producer ./mvnw clean package ~/data-consumer ./mvnw clean package ~/ docker build -f data-producer/src/main/docker/Dockerfile.multistage -t data-producer:native data-producer/. ~/ docker build -f data-consumer/src/main/docker/Dockerfile.multistage -t data-consumer:native data-consumer/.  Now start the built native images. You will realize that the startup time is almost instantaneous.\n__ ____ __ _____ ___ __ ____ ______ --/ __ \\/ / / / _ | / _ \\/ //_/ / / / __/ -/ /_/ / /_/ / __ |/ , _/ ,\u0026lt; / /_/ /\\ \\ --\\___\\_\\____/_/ |_/_/|_/_/|_|\\____/___/ 2020-08-31 15:02:53,244 INFO [io.quarkus] (main) data-consumer 1.0-SNAPSHOT native (powered by Quarkus 1.7.0.Final) started in 0.031s. Listening on: http://0.0.0.0:8080 2020-08-31 15:02:53,244 INFO [io.quarkus] (main) Profile prod activated. 2020-08-31 15:02:53,244 INFO [io.quarkus] (main) Installed features: [cdi, rest-client, resteasy, resteasy-jsonb, smallrye-health] ","excerpt":"3.3.1 As the name says, native builds will run the Quarkus application as a native executable. The …","ref":"/quarkus-techlab/docs/03.0/native-build/","title":"3.3 Native Build"},{"body":"4.1.1 For the next chapter we need to prepare our applications to run in a cloud environment. One important aspect of this will be adding health checks to our applications. Implementing or adding health checks to your Quarkus application is - as expected - easy. Simply add the extension \u0026lsquo;smallrye-health\u0026rsquo; to your applications with the following command:\n./mvnw quarkus:add-extension -Dextensions=\u0026#34;quarkus-smallrye-health\u0026#34; When you restart your applications they both will expose automatically the \u0026lsquo;/health\u0026rsquo; endpoint which indicates that the application is up and running.\nAdditionally we need to configure the connection from our data-consumer to the data-producer. As for now the data-consumer simply points to the url configured in the application.properties which gets injected to the defined RestClient.\nExtend your application.properties of the data-consumer to:\nquarkus.http.port=8080 %dev.quarkus.http.port=8081 application.data-producer.url=data-producer %dev.application.data-producer.url=localhost application.data-producer.port=8080 %dev.application.data-producer.port=8080 data-producer-api/mp-rest/url=http://${application.data-producer.url}:${application.data-producer.port} data-producer-api/mp-rest/scope=javax.inject.Singleton The prefix %dev. in front of a configuration property defines a quarkus profile. Whenever the defined profile is active the value will be overwritten.\n","excerpt":"4.1.1 For the next chapter we need to prepare our applications to run in a cloud environment. One …","ref":"/quarkus-techlab/docs/04.0/configuration/","title":"4.1 Configuration"},{"body":"4.2.1: Defining Resources To build our simple applications we need for each part an ImageStream, DeploymentConfig and Service. To define the needed resources create a template folder in your applications repository (src/main/openshift/templates) and add a new file to it data-producer.yml / data-consumer.yml:\n-- data-consumer.ymlapiVersion:v1kind:Listmetadata:labels:application:quarkus-techlabitems:- apiVersion:v1kind:ImageStreammetadata:labels:application:quarkus-techlabname:data-consumer- apiVersion:v1kind:DeploymentConfigmetadata:labels:application:quarkus-techlabname:data-consumerspec:replicas:1selector:deploymentConfig:data-consumerstrategy:type:Recreatetemplate:metadata:labels:application:quarkus-techlabdeploymentConfig:data-consumerspec:containers:- image:data-consumerimagePullPolicy:AlwayslivenessProbe:failureThreshold:5httpGet:path:/healthport:8080scheme:HTTPinitialDelaySeconds:3periodSeconds:20successThreshhold:1timeoutSeconds:15readinessProbe:failureThreshold:5httpGet:path:/healthport:8080scheme:HTTPinitialDelaySeconds:3periodSeconds:20successThreshold:1timeoutSeconds:15name:data-consumerport:- containerPort:8080name:httpprotocol:TCPresources:limits:cpu:1memory:500Mirequests:cpu:50mmemory:100Mitriggers:- imageChangeParams:automatic:truecontainerNames:- data-consumerfrom:kind:ImageStreamTagname:data-consumer:latesttype:ImageChange- type:ConfigChange- apiVersion:v1kind:Servicemetadata:labels:application:quarkus-techlabname:data-consumerspec:ports:- name:data-consumer-httpport:8080protocol:TCPtargetPort:8080selector:deploymentConfig:data-consumersessionAffinity:Nonetype:ClusterIPThis defines a list of OpenShift resources containing the ImageStream, DeploymentConfig and Service for the application. To read more about OpenShift or Kubernetes resources please see the official documentations.\n4.2.2: Applying our resources To continue we will log into our cluster:\noc login --server=https://${OCP_URL}\u0026gt;:${OCP_PORT} We then create a new project\noc new-project quarkus-techlab-userXY oc project quarkus-techlab-userXY Then we will apply our defined resources with:\noc apply -f data-consumer/src/main/openshift/templates The output should confirm that the three resources have been generated successfully.\n4.2.3: Start a deployment Due to the fact that we defined an trigger on ImageChange in the DeploymentConfig a deployment starts whenever we push or tag a new image to our ImageStream. To deploy our application we simply tag and push our images to the registry.\n// Tag images docker tag data-producer:native $REGISTRY/$OPENSHIFT_PROJECT/data-producer:latest docker tag data-consumer:native $REGISTRY/$OPENSHIFT_PROJECT/data-consumer:latest // TODO: Insert correct registry link docker login -u $USERNAME $REGISTRY -p $(oc whoami -t) // Push images docker push $REGISTRY/$OPENSHIFT_PROJECT/data-producer:latest docker push $REGISTRY/$OPENSHIFT_PROJECT/data-consumer:latest When the image is pushed OpenShift will automatically rollout your application. To verify your deployment use the oc tool to watch the pods in your project:\noc get pods -w You will see that two pods will start data-producer-1-***** and data-consumer-1-*****. After a short time the readiness probes should succeed and both pods will change their status to Running, which means your application is ready to use!\nCreate a route to the data-consumer service with:\noc expose svc data-consumer Now test your data-consumer application with:\ncurl http://$(oc get route data-consumer -o go-template --template=\u0026#39;{{.spec.host}}\u0026#39;)/data You should see the response given from the application in the expected format.\nNice, our application now runs in the clouds!\n","excerpt":"4.2.1: Defining Resources To build our simple applications we need for each part an ImageStream, …","ref":"/quarkus-techlab/docs/04.0/openshift/","title":"4.2 OpenShift"},{"body":"In this example we are going to build a CI/CD pipeline to apply our current manifests (OpenShift Resources), build our image and push it into our docker-registry. To define a minimal pipeline we need at least a Task, a Pipeline and PipelineResources which are going to be used by our Pipeline.\n5.1.1: Define our first Task Let\u0026rsquo;s define our first Task resource. We talked about applying our manifests to our existing OpenShift namespace. Our Task to apply our manifests will look something like this:\napiVersion:tekton.dev/v1alpha1kind:Taskmetadata:name:apply-manifestsspec:resources:inputs:- type:gitname:sourceparams:- name:manifest_dirdescription:The directory in source that contains yaml manifeststype:stringdefault:\u0026#34;src/main/openshift/templates\u0026#34;steps:- name:applyimage:appuio/oc:v4.3workingDir:/workspacecommand:[\u0026#34;/bin/bash\u0026#34;,\u0026#34;-c\u0026#34;]args:- |- echo Applying manifests in $(inputs.params.manifest_dir) directory oc apply -f source/$(inputs.params.manifest_dir) echo ----------------------------------- We define that we will need a input Resource (PipelineResource) of type git (Git-Repository), we can use a parameter called \u0026lsquo;manifest_dir\u0026rsquo; to define where our templates reside which we are going to apply. In the specification (spec:) we define a set of steps which are executed in this specific Task.\nIn this example Task we can see that we will use a container appuio/oc:v4.3 which provides us an image with provided OpenShift CLI (oc) available. We start the container with the defined arguments which are going to apply our manifests on the used namespace.\n5.1.2: Define the Pipeline After we have taken a look at the Task we are going to execute we will take a look at the entire Pipeline. The Pipeline will look like this:\napiVersion:tekton.dev/v1alpha1kind:Pipelinemetadata:name:apply-and-buildspec:resources:- name:git-repotype:git- name:imagetype:imageparams:- name:deployment-nametype:stringdescription:Name of the deployment to be patched- name:docker-filedescription:Path to the Dockerfiletype:stringdefault:src/main/docker/Dockerfile.multistagetasks:- name:apply-manifeststaskRef:name:apply-manifestsresources:inputs:- name:sourceresource:git-repo- name:build-imagetaskRef:name:buildahkind:ClusterTaskresources:inputs:- name:sourceresource:git-repooutputs:- name:imageresource:imagerunAfter:- apply-manifestsparams:- name:TLSVERIFYvalue:\u0026#34;false\u0026#34;- name:DOCKERFILEvalue:$(params.docker-file)We can see that we are going to use two PipelineResources, a git repository ({type: git, name: git-repo}) and a image reference ({type: image, name: image}). We can parameterize our Pipeline with the parameters deployent-name which will specify the microservice we will build and deploy and the parameter docker-file which will be passed into the second step to define where our Dockerfile\u0026rsquo;s location is. In the tasks specification we define which Tasks the Pipeline will execute. We can define the behaviour of execution of these Tasks with additional flags, for example we define that the Task build-image will be runned after apply-manifests with the runAfter element. You can see now that the workflow passes the defined PipelineResources for one Task to another as defined inputs and outputs. The Task build-image is a predefined ClusterTask which comes with the Tekton Operator installation on our OpenShift cluster.\n5.1.3: Define PipelineResources We already defined the Pipeline and Tasks which we are going to use to build and deploy our Quarkus application. The missing parts are the PipelineResources we used in our Pipeline defined in the specification of our Pipeline and Tasks. Let\u0026rsquo;s create these PipelineResources so we can test our defined Pipeline.\napiVersion:v1kind:Listmetadata:labels:application:quarkus-techlabitems:- apiVersion:tekton.dev/v1alpha1kind:PipelineResourcemetadata:name:data-producer-repospec:type:gitparams:- name:urlvalue:https://github.com/g1raffi/quarkus-techlab-data-producer.git- apiVersion:tekton.dev/v1alpha1kind:PipelineResourcemetadata:name:data-producer-imagespec:type:imageparams:- name:urlvalue:image-registry.openshift-image-registry.svc:5000/quarkus-techlab/data-producer:latest- apiVersion:tekton.dev/v1alpha1kind:PipelineResourcemetadata:name:data-consumer-repospec:type:gitparams:- name:urlvalue:https://github.com/g1raffi/quarkus-techlab-data-consumer.git- apiVersion:tekton.dev/v1alpha1kind:PipelineResourcemetadata:name:data-consumer-imagespec:type:imageparams:- name:urlvalue:image-registry.openshift-image-registry.svc:5000/quarkus-techlab/data-consumer:latestThis defines a List of PipelineResources with four elements, for each application we define a git-repository of type git and an image reference of type image.\n5.1.4: Apply the Pipeline Create a directory / module to hold your infrastructure objects quarkus-techlab-infrastructure and save these resource definitions under quarkus-techlab-infrastructure/src/main/openshift/tekton. Make sure you are in your defined namespace and apply these resources:\noc apply -f quarkus-techlab-infrastructure/src/main/openshift/tekton You will see that the the resources will be created.\n$ oc apply -f quarkus-techlab-infrastructure/src/main/openshift/tekton pipeline.tekton.dev/apply-and-build created task.tekton.dev/apply-manifests created pipelineresource.tekton.dev/data-producer-repo created pipelineresource.tekton.dev/data-producer-image created pipelineresource.tekton.dev/data-consumer-repo created pipelineresource.tekton.dev/data-consumer-image created 5.1.5: Start and run the pipeline To run your newly defined Pipeline you will use the Tekton binary (tkn). Simply run the following command to start a PipelineRun of your defined Pipeline.\nFirst add a multistage Dockerfile for JVM builds to your two repositories:\n# quarkus-techlab-data-consumer/src/main/docker/Dockerfile.multistage.jvm## Stage 1 : build with maven builder image with native capabilitiesFROMquay.io/quarkus/centos-quarkus-maven:20.1.0-java11 AS buildCOPY pom.xml /usr/src/app/RUN mvn -f /usr/src/app/pom.xml -B de.qaware.maven:go-offline-maven-plugin:1.2.5:resolve-dependenciesCOPY src /usr/src/app/srcUSERrootRUN chown -R quarkus /usr/src/appUSERquarkusRUN mvn -f /usr/src/app/pom.xml clean package## Stage 2 : create the docker final imageFROMregistry.access.redhat.com/ubi8/ubi-minimal:8.1ARG JAVA_PACKAGE=java-11-openjdk-headlessARG RUN_JAVA_VERSION=1.3.8ENV LANG=\u0026#39;en_US.UTF-8\u0026#39; LANGUAGE=\u0026#39;en_US:en\u0026#39;# Install java and the run-java script# Also set up permissions for user `1001`RUN microdnf install curl ca-certificates ${JAVA_PACKAGE} \\  \u0026amp;\u0026amp; microdnf update \\  \u0026amp;\u0026amp; microdnf clean all \\  \u0026amp;\u0026amp; mkdir /deployments \\  \u0026amp;\u0026amp; chown 1001 /deployments \\  \u0026amp;\u0026amp; chmod \u0026#34;g+rwX\u0026#34; /deployments \\  \u0026amp;\u0026amp; chown 1001:root /deployments \\  \u0026amp;\u0026amp; curl https://repo1.maven.org/maven2/io/fabric8/run-java-sh/${RUN_JAVA_VERSION}/run-java-sh-${RUN_JAVA_VERSION}-sh.sh -o /deployments/run-java.sh \\  \u0026amp;\u0026amp; chown 1001 /deployments/run-java.sh \\  \u0026amp;\u0026amp; chmod 540 /deployments/run-java.sh \\  \u0026amp;\u0026amp; echo \u0026#34;securerandom.source=file:/dev/urandom\u0026#34; \u0026gt;\u0026gt; /etc/alternatives/jre/lib/security/java.security# Configure the JAVA_OPTIONS, you can add -XshowSettings:vm to also display the heap size.ENV JAVA_OPTIONS=\u0026#34;-Dquarkus.http.host=0.0.0.0 -Djava.util.logging.manager=org.jboss.logmanager.LogManager\u0026#34;COPY --from=build /usr/src/app/target/lib/* /deployments/lib/COPY --from=build /usr/src/app/target/*-runner.jar /deployments/app.jarEXPOSE8080USER1001ENTRYPOINT [ \u0026#34;/deployments/run-java.sh\u0026#34; ]tkn pipeline start apply-and-build -r git-repo=data-consumer-repo -r image=data-consumer-image -p deployment-name=data-consumer -p docker-file=src/main/docker/Dockerfile.multistage.jvm -s pipeline Tekton will prompt you with a command to follow the logs of the started PipelineRun. If you enter the prompted command you will follow the PipelineRuns logs on your command line.\n5.1.6: What did just happen We declared in this chapter our first own CI/CD Pipelines as Kubernetes-native resources. We defined a Pipeline which uses multiple PipelineResources in it\u0026rsquo;s Tasks to apply our manifests, build and deploy our applications.\nUpdate your microservices, change the infrastructure declaration and test your deployment again!\n","excerpt":"In this example we are going to build a CI/CD pipeline to apply our current manifests (OpenShift …","ref":"/quarkus-techlab/docs/05.0/defining-pipelines/","title":"5.1 Defining pipelines"},{"body":"6.1.1: ActiveMQ Artemis In order to make our microservices to communicate through messaging we need to setup a message broker first. In this first example we are going to use Artemis ActiveM as our message broker. Artemis provides us a simple message broker which comes with a few handy features which we are going to make use of.\nTo setup our Artemis ActiveMQ instance we are going to use a docker image and run it locally:\ndocker run -it --rm -p 8161:8161 -p 61616:61616 -p 5672:5672 -e ARTEMIS_USERNAME=quarkus -e ARTEMIS_PASSWORD=quarkus vromero/activemq-artemis:2.11.0-alpine If you have your container up and running you can log into the web UI on http://localhost:8161/console and click yourself through the interface.\n6.1.2: Microservices In order to use messaging instead of REST calls we do need to change our implementation. If you like you can leave the entire REST implementation and just create a new package artemis inside your application.\nIn order to use messaging we are going to use the Quarkus extension \u0026ldquo;quarkus-artemis-jms\u0026rdquo;, add this extension to your producer and consumer project.\n./quarkus-techlab-data-consumer/mvnw quarkus:add-extension -Dextensions=\u0026#34;quarkus-artemis-jms\u0026#34; ./quarkus-techlab-data-producer/mvnw quarkus:add-extension -Dextensions=\u0026#34;quarkus-artemis-jms\u0026#34; Let\u0026rsquo;s start with producing data to a Queue:\n6.1.2.1: Producing data We are going to implement a new Class called DataProducer ch.puzzle.quarkustechlab.jmsproducer.boundary.JmsDataProducer which implements the Interface Runnable. We setup a simple Scheduler which triggers the production of a Message every five seconds with a random SensorMeasurement.\n@ApplicationScoped public class JmsDataProducer implements Runnable { @Inject ConnectionFactory connectionFactory; private final ScheduledExecutorService scheduler = Executors.newSingleThreadScheduledExecutor(); void onStart(@Observes StartupEvent event) { scheduler.scheduleWithFixedDelay(this, 0L, 5L, TimeUnit.SECONDS); } void onStop(@Observes ShutdownEvent event) { scheduler.shutdown(); } @Override public void run() { try(JMSContext context = connectionFactory.createContext(Session.AUTO_ACKNOWLEDGE)) { context.createProducer().send(context.createQueue(\u0026#34;data-inbound\u0026#34;), JsonbBuilder.create().toJson(new SensorMeasurement())); } } } We need to setup the ConnectionFactory so our microservices know how to communicate with our Artemis message broker. We add the following properties to our application.properties files in both microservices:\n# Configures the Qpid JMS properties.quarkus.artemis.url=tcp://artemis-activemq:61616%dev.quarkus.artemis.url=tcp://localhost:61616quarkus.artemis.username=quarkusquarkus.artemis.password=quarkus6.1.2.2: Consuming data On the consumer side we create a new Class ch.puzzle.quarkustechlab.jmsconsumer.boundary.JmsDataConsumer which also implements the Interface Runnable:\n@ApplicationScoped public class JmsDataConsumer implements Runnable { @Inject ConnectionFactory connectionFactory; private final Logger logger = Logger.getLogger(JMSConsumer.class.getName()); private final ExecutorService scheduler = Executors.newSingleThreadScheduledExecutor(); private volatile SensorMeasurement lastData; public SensorMeasurement getLastData() { return lastData; } void onStart(@Observes StartupEvent event) { scheduler.submit(this); } void onShutDown(@Observes ShutdownEvent event) { scheduler.shutdown(); } @Override public void run() { try (JMSContext context = connectionFactory.createContext(Session.AUTO_ACKNOWLEDGE)) { JMSConsumer consumer = context.createConsumer(context.createQueue(\u0026#34;data-inbound\u0026#34;)); while (true) { Message message = consumer.receive(); if (message == null) return; logger.info(\u0026#34;Receieved data: \u0026#34; + message.getBody(String.class)); lastData = JsonbBuilder.create().fromJson(message.getBody(String.class), SensorMeasurement.class); } } catch (JMSException e) { throw new RuntimeException(e); } } } Let\u0026rsquo;s create a REST resource to see the lastData property consumed:\n@Path(\u0026#34;/jms/data\u0026#34;) public class JmsDataResource { @Inject JmsDataConsumer consumer; @GET @Produces(MediaType.APPLICATION_JSON) public SensorMeasurement getData() { return consumer.getLastData(); } } If you run both applications you will see that the consumer receives an Message every five seconds with new data from the message broker. If you check the Artemis UI you can see under \u0026lsquo;Diagram\u0026rsquo; your Queue with an active consumer connected to it. When you head over to the \u0026lsquo;Queues\u0026rsquo; tab you can read or manipulate your Queues manually. You can also use your defined REST resource to check the data.\n","excerpt":"6.1.1: ActiveMQ Artemis In order to make our microservices to communicate through messaging we need …","ref":"/quarkus-techlab/docs/06.0/artemis/","title":"6.1 ActiveMQ Artemis"},{"body":"Let\u0026rsquo;s configure our microservices and message broker on OpenShift so we can test this in our production ready environment.\nCreate the artemis resources:\nparameters:- name:METADATA_LABELS_APPLICATIONvalue:quarkus-techlab-user- name:METADATA_LABELS_TEMPLATEvalue:quarkus-techlab-template- name:ARTEMIS_SERVICE_NAMEdescription:Name for the openshift servicevalue:artemis-activemq- name:ARTEMIS_IMAGE_NAMEvalue:vromero/activemq-artemis- name:ARTEMIS_IMAGE_TAGvalue:2.10.1- name:ARTEMIS_VOLUME_CLAIM_SIZEdescription:Amount of data for the pvc for artemisvalue:1Gi- name:ARTEMIS_DISABLE_SECURITYdescription:Enables non-tls connectionsvalue:\u0026#34;true\u0026#34;- name:ARTEMIS_RESTORE_CONFIGURATIONdescription:Restores configurations on container startupvalue:\u0026#34;true\u0026#34;- name:ARTEMIS_ENABLE_JMX_EXPORTERdescription:Enables the jmx exporter functionvalue:\u0026#34;true\u0026#34;- name:ARTEMIS_ANONYMOUS_LOGINdescription:Allows anonymous login for the artemis activemq systemvalue:\u0026#34;false\u0026#34;- name:ARTEMIS_PORT_MQTTdescription:Port for MQTTvalue:\u0026#34;1883\u0026#34;- name:ARTEMIS_PORT_WEB_SERVERdescription:Port for the web servervalue:\u0026#34;8161\u0026#34;- name:ARTEMIS_PORT_HORNETQdescription:Port for HORNETQvalue:\u0026#34;5445\u0026#34;- name:ARTEMIS_PORT_AMQPdescription:Port for AMQPvalue:\u0026#34;5672\u0026#34;- name:ARTEMIS_PORT_JMX_EXPORTERdescription:Port for the jmx exporter for prometheusvalue:\u0026#34;9404\u0026#34;- name:ARTEMIS_PORT_STOMPdescription:Port for STOMPvalue:\u0026#34;61613\u0026#34;- name:ARTEMIS_PORT_COREdescription:Port for the core apivalue:\u0026#34;61616\u0026#34;- name:ARTEMIS_CPU_LIMITvalue:500m- name:ARTEMIS_MEMORY_LIMITvalue:2Gi- name:ARTEMIS_CPU_REQUESTvalue:200m- name:ARTEMIS_MEMORY_REQUESTvalue:1Gi- name:ROUTE_ARTEMIS_HOSTdescription:Route for the artemis web uivalue:artemis-quarkus-techlab.ocp.aws.chkind:TemplateapiVersion:v1metadata:name:b4u-application-templateannotations:iconClass:icon-javatags:java,microservice,b4uobjects:- apiVersion:v1kind:ImageStreammetadata:labels:application:${METADATA_LABELS_APPLICATION}template:${METADATA_LABELS_TEMPLATE}name:${ARTEMIS_SERVICE_NAME}spec:lookupPolicy:local:falsetags:- from:kind:DockerImagename:${ARTEMIS_IMAGE_NAME}:${ARTEMIS_IMAGE_TAG}name:${ARTEMIS_IMAGE_TAG}- apiVersion:v1kind:PersistentVolumeClaimmetadata:labels:application:${METADATA_LABELS_APPLICATION}template:${METADATA_LABELS_TEMPLATE}name:artemis-dataspec:accessModes:- ReadWriteOnceresources:requests:storage:${ARTEMIS_VOLUME_CLAIM_SIZE}- apiVersion:v1kind:DeploymentConfigmetadata:labels:application:${METADATA_LABELS_APPLICATION}template:${METADATA_LABELS_TEMPLATE}name:${ARTEMIS_SERVICE_NAME}spec:replicas:1selector:deploymentConfig:${ARTEMIS_SERVICE_NAME}strategy:type:Recreatetemplate:metadata:labels:application:${METADATA_LABELS_APPLICATION}deploymentConfig:${ARTEMIS_SERVICE_NAME}name:${ARTEMIS_SERVICE_NAME}spec:containers:- env:- name:ARTEMIS_USERNAMEvalue:quarkus- name:ARTEMIS_PASSWORDvalue:quarkus- name:ANONYMOUS_LOGINvalue:${ARTEMIS_ANONYMOUS_LOGIN}- name:DISABLE_SECURITYvalue:${ARTEMIS_DISABLE_SECURITY}- name:RESTORE_CONFIGURATIONvalue:${ARTEMIS_RESTORE_CONFIGURATION}- name:ENABLE_JMX_EXPORTERvalue:${ARTEMIS_ENABLE_JMX_EXPORTER}image:${ARTEMIS_IMAGE_NAME}imagePullPolicy:AlwayslivenessProbe:failureThreshold:5successThreshold:1httpGet:path:/port:8161scheme:HTTPinitialDelaySeconds:120preiodSeconds:20timeoutSeconds:15readinessProbe:failureThreshold:5successThreshold:1httpGet:path:/port:8161scheme:HTTPinitialDelaySeconds:30preiodSeconds:20timeoutSeconds:15resources:limits:cpu:${ARTEMIS_CPU_LIMIT}memory:${ARTEMIS_MEMORY_LIMIT}requests:cpu:${ARTEMIS_CPU_REQUEST}memory:${ARTEMIS_MEMORY_REQUEST}volumeMounts:- name:artemis-datamountPath:/var/lib/artemis/data- name:artemis-config-overridemountPath:/var/lib/artemis/etc-override- name:artemis-config-dirmountPath:/var/lib/artemis/etc- name:artemis-lockmountPath:/var/lib/artemis/lock- name:artemis-tempmountPath:/var/lib/artemis/tmpname:${ARTEMIS_SERVICE_NAME}ports:- containerPort:1883name:mqttprotocol:TCP- containerPort:5445name:hornetqprotocol:TCP- containerPort:5672name:amqpprotocol:TCP- containerPort:8161name:webserverprotocol:TCP- containerPort:9404name:jmxprotocol:TCP- containerPort:61613name:stompprotocol:TCP- containerPort:61616name:coreprotocol:TCPvolumes:- name:artemis-datapersistentVolumeClaim:claimName:artemis-data- name:artemis-config-overrideconfigMap:name:artemis-config- name:artemis-config-diremptyDir:{}- name:artemis-lockemptyDir:{}- name:artemis-tempemptyDir:{}triggers:- imageChangeParams:automatic:truecontainerNames:- ${ARTEMIS_SERVICE_NAME}from:kind:ImageStreamTagname:${ARTEMIS_SERVICE_NAME}:${ARTEMIS_IMAGE_TAG}type:ImageChange- type:ConfigChange- apiVersion:v1kind:Servicemetadata:annotations:prometheus.io/scrape:\u0026#34;true\u0026#34;prometheus.io/path:\u0026#34;/\u0026#34;prometheus.io/port:${ARTEMIS_PORT_JMX_EXPORTER}labels:application:${METADATA_LABELS_APPLICATION}template:${METADATA_LABELS_TEMPLATE}prometheus-monitoring:\u0026#34;true\u0026#34;monitoring:${ARTEMIS_SERVICE_NAME}name:${ARTEMIS_SERVICE_NAME}spec:ports:- name:artemis-mqttport:1883targetPort:1883protocol:TCP- name:artemis-hornetqport:5445targetPort:5445protocol:TCP- name:artemis-amqpport:5672targetPort:5672protocol:TCP- name:artemis-web-serverport:8161targetPort:8161protocol:TCP- name:artemis-jmx-exporterport:9404targetPort:9404protocol:TCP- name:artemis-stompport:61613targetPort:61613protocol:TCP- name:artemis-coreport:61616targetPort:61616protocol:TCPselector:deploymentConfig:${ARTEMIS_SERVICE_NAME}sessionAffinity:Nonetype:ClusterIP- apiVersion:v1kind:Routemetadata:labels:application:${METADATA_LABELS_APPLICATION}template:${METADATA_LABELS_TEMPLATE}name:artemis-routespec:host:${ROUTE_ARTEMIS_HOST}port:targetPort:artemis-web-servertls:insecureEdgeTerminationPolicy:Redirecttermination:edgeto:kind:Servicename:${ARTEMIS_SERVICE_NAME}wildcardPolicy:None- apiVersion:v1kind:ConfigMapmetadata:labels:application:${METADATA_LABELS_APPLICATION}template:${METADATA_LABELS_TEMPLATE}name:artemis-configdata:broker-1.xml:|- \u0026lt;?xml version=\u0026#39;1.0\u0026#39;?\u0026gt; \u0026lt;configuration xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns=\u0026#34;urn:activemq\u0026#34; xsi:schemaLocation=\u0026#34;urn:activemq /schema/artemis-configuration.xsd\u0026#34;\u0026gt; \u0026lt;core xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xmlns=\u0026#34;urn:activemq:core\u0026#34; xsi:schemaLocation=\u0026#34;urn:activemq:core \u0026#34;\u0026gt; \u0026lt;name\u0026gt;quarkus-techlab-artemis\u0026lt;/name\u0026gt; \u0026lt;persistence-enabled\u0026gt;true\u0026lt;/persistence-enabled\u0026gt; \u0026lt;!-- this could be ASYNCIO, MAPPED, NIO ASYNCIO: Linux Libaio MAPPED: mmap files NIO: Plain Java Files --\u0026gt; \u0026lt;journal-type\u0026gt;ASYNCIO\u0026lt;/journal-type\u0026gt; \u0026lt;paging-directory\u0026gt;data/paging\u0026lt;/paging-directory\u0026gt; \u0026lt;bindings-directory\u0026gt;data/bindings\u0026lt;/bindings-directory\u0026gt; \u0026lt;journal-directory\u0026gt;data/journal\u0026lt;/journal-directory\u0026gt; \u0026lt;large-messages-directory\u0026gt;data/large-messages\u0026lt;/large-messages-directory\u0026gt; \u0026lt;journal-datasync\u0026gt;true\u0026lt;/journal-datasync\u0026gt; \u0026lt;journal-min-files\u0026gt;2\u0026lt;/journal-min-files\u0026gt; \u0026lt;journal-pool-files\u0026gt;10\u0026lt;/journal-pool-files\u0026gt; \u0026lt;journal-device-block-size\u0026gt;4096\u0026lt;/journal-device-block-size\u0026gt; \u0026lt;journal-file-size\u0026gt;10M\u0026lt;/journal-file-size\u0026gt; \u0026lt;!-- This value was determined through a calculation. Your system could perform 62.5 writes per millisecond on the current journal configuration. That translates as a sync write every 16000 nanoseconds. Note: If you specify 0 the system will perform writes directly to the disk. We recommend this to be 0 if you are using journalType=MAPPED and journal-datasync=false. --\u0026gt; \u0026lt;journal-buffer-timeout\u0026gt;16000\u0026lt;/journal-buffer-timeout\u0026gt; \u0026lt;!-- When using ASYNCIO, this will determine the writing queue depth for libaio. --\u0026gt; \u0026lt;journal-max-io\u0026gt;4096\u0026lt;/journal-max-io\u0026gt; \u0026lt;!-- You can verify the network health of a particular NIC by specifying the \u0026lt;network-check-NIC\u0026gt; element. \u0026lt;network-check-NIC\u0026gt;theNicName\u0026lt;/network-check-NIC\u0026gt; --\u0026gt; \u0026lt;!-- Use this to use an HTTP server to validate the network \u0026lt;network-check-URL-list\u0026gt;http://www.apache.org\u0026lt;/network-check-URL-list\u0026gt; --\u0026gt; \u0026lt;!-- \u0026lt;network-check-period\u0026gt;10000\u0026lt;/network-check-period\u0026gt; --\u0026gt; \u0026lt;!-- \u0026lt;network-check-timeout\u0026gt;1000\u0026lt;/network-check-timeout\u0026gt; --\u0026gt; \u0026lt;!-- this is a comma separated list, no spaces, just DNS or IPs it should accept IPV6 Warning: Make sure you understand your network topology as this is meant to validate if your network is valid. Using IPs that could eventually disappear or be partially visible may defeat the purpose. You can use a list of multiple IPs, and if any successful ping will make the server OK to continue running --\u0026gt; \u0026lt;!-- \u0026lt;network-check-list\u0026gt;10.0.0.1\u0026lt;/network-check-list\u0026gt; --\u0026gt; \u0026lt;!-- use this to customize the ping used for ipv4 addresses --\u0026gt; \u0026lt;!-- \u0026lt;network-check-ping-command\u0026gt;ping -c 1 -t %d %s\u0026lt;/network-check-ping-command\u0026gt; --\u0026gt; \u0026lt;!-- use this to customize the ping used for ipv6 addresses --\u0026gt; \u0026lt;!-- \u0026lt;network-check-ping6-command\u0026gt;ping6 -c 1 %2$s\u0026lt;/network-check-ping6-command\u0026gt; --\u0026gt; \u0026lt;!-- how often we are looking for how many bytes are being used on the disk in ms --\u0026gt; \u0026lt;disk-scan-period\u0026gt;5000\u0026lt;/disk-scan-period\u0026gt; \u0026lt;!-- once the disk hits this limit the system will block, or close the connection in certain protocols that won\u0026#39;t support flow control. --\u0026gt; \u0026lt;max-disk-usage\u0026gt;90\u0026lt;/max-disk-usage\u0026gt; \u0026lt;!-- should the broker detect dead locks and other issues --\u0026gt; \u0026lt;critical-analyzer\u0026gt;true\u0026lt;/critical-analyzer\u0026gt; \u0026lt;critical-analyzer-timeout\u0026gt;120000\u0026lt;/critical-analyzer-timeout\u0026gt; \u0026lt;critical-analyzer-check-period\u0026gt;60000\u0026lt;/critical-analyzer-check-period\u0026gt; \u0026lt;critical-analyzer-policy\u0026gt;HALT\u0026lt;/critical-analyzer-policy\u0026gt; \u0026lt;!-- the system will enter into page mode once you hit this limit. This is an estimate in bytes of how much the messages are using in memory The system will use half of the available memory (-Xmx) by default for the global-max-size. You may specify a different value here if you need to customize it to your needs. \u0026lt;global-max-size\u0026gt;100Mb\u0026lt;/global-max-size\u0026gt; --\u0026gt; \u0026lt;acceptors\u0026gt; \u0026lt;!-- useEpoll means: it will use Netty epoll if you are on a system (Linux) that supports it --\u0026gt; \u0026lt;!-- amqpCredits: The number of credits sent to AMQP producers --\u0026gt; \u0026lt;!-- amqpLowCredits: The server will send the # credits specified at amqpCredits at this low mark --\u0026gt; \u0026lt;!-- Note: If an acceptor needs to be compatible with HornetQ and/or Artemis 1.x clients add \u0026#34;anycastPrefix=jms.queue.;multicastPrefix=jms.topic.\u0026#34; to the acceptor url. See https://issues.apache.org/jira/browse/ARTEMIS-1644 for more information. --\u0026gt; \u0026lt;!-- Acceptor for every supported protocol --\u0026gt; \u0026lt;acceptor name=\u0026#34;artemis\u0026#34;\u0026gt; tcp://0.0.0.0:61616?tcpSendBufferSize=1048576;tcpReceiveBufferSize=1048576;protocols=CORE,AMQP,STOMP,HORNETQ,MQTT,OPENWIRE;useEpoll=true;amqpCredits=1000;amqpLowCredits=300 \u0026lt;/acceptor\u0026gt; \u0026lt;!-- AMQP Acceptor. Listens on default AMQP port for AMQP traffic.--\u0026gt; \u0026lt;acceptor name=\u0026#34;amqp\u0026#34;\u0026gt; tcp://0.0.0.0:5672?tcpSendBufferSize=1048576;tcpReceiveBufferSize=1048576;protocols=AMQP;useEpoll=true;amqpCredits=1000;amqpLowCredits=300 \u0026lt;/acceptor\u0026gt; \u0026lt;!-- STOMP Acceptor. --\u0026gt; \u0026lt;acceptor name=\u0026#34;stomp\u0026#34;\u0026gt; tcp://0.0.0.0:61613?tcpSendBufferSize=1048576;tcpReceiveBufferSize=1048576;protocols=STOMP;useEpoll=true \u0026lt;/acceptor\u0026gt; \u0026lt;!-- HornetQ Compatibility Acceptor. Enables HornetQ Core and STOMP for legacy HornetQ clients. --\u0026gt; \u0026lt;acceptor name=\u0026#34;hornetq\u0026#34;\u0026gt; tcp://0.0.0.0:5445?anycastPrefix=jms.queue.;multicastPrefix=jms.topic.;protocols=HORNETQ,STOMP;useEpoll=true \u0026lt;/acceptor\u0026gt; \u0026lt;!-- MQTT Acceptor --\u0026gt; \u0026lt;acceptor name=\u0026#34;mqtt\u0026#34;\u0026gt;tcp://0.0.0.0:1883?tcpSendBufferSize=1048576;tcpReceiveBufferSize=1048576;protocols=MQTT;useEpoll=true \u0026lt;/acceptor\u0026gt; \u0026lt;/acceptors\u0026gt; \u0026lt;security-settings\u0026gt; \u0026lt;security-setting match=\u0026#34;#\u0026#34;\u0026gt; \u0026lt;permission type=\u0026#34;createNonDurableQueue\u0026#34; roles=\u0026#34;amq\u0026#34;/\u0026gt; \u0026lt;permission type=\u0026#34;deleteNonDurableQueue\u0026#34; roles=\u0026#34;amq\u0026#34;/\u0026gt; \u0026lt;permission type=\u0026#34;createDurableQueue\u0026#34; roles=\u0026#34;amq\u0026#34;/\u0026gt; \u0026lt;permission type=\u0026#34;deleteDurableQueue\u0026#34; roles=\u0026#34;amq\u0026#34;/\u0026gt; \u0026lt;permission type=\u0026#34;createAddress\u0026#34; roles=\u0026#34;amq\u0026#34;/\u0026gt; \u0026lt;permission type=\u0026#34;deleteAddress\u0026#34; roles=\u0026#34;amq\u0026#34;/\u0026gt; \u0026lt;permission type=\u0026#34;consume\u0026#34; roles=\u0026#34;amq\u0026#34;/\u0026gt; \u0026lt;permission type=\u0026#34;browse\u0026#34; roles=\u0026#34;amq\u0026#34;/\u0026gt; \u0026lt;permission type=\u0026#34;send\u0026#34; roles=\u0026#34;amq\u0026#34;/\u0026gt; \u0026lt;!-- we need this otherwise ./artemis data imp wouldn\u0026#39;t work --\u0026gt; \u0026lt;permission type=\u0026#34;manage\u0026#34; roles=\u0026#34;amq\u0026#34;/\u0026gt; \u0026lt;/security-setting\u0026gt; \u0026lt;/security-settings\u0026gt; \u0026lt;address-settings\u0026gt; \u0026lt;!-- if you define auto-create on certain queues, management has to be auto-create --\u0026gt; \u0026lt;address-setting match=\u0026#34;activemq.management#\u0026#34;\u0026gt; \u0026lt;dead-letter-address\u0026gt;DLQ\u0026lt;/dead-letter-address\u0026gt; \u0026lt;expiry-address\u0026gt;ExpiryQueue\u0026lt;/expiry-address\u0026gt; \u0026lt;redelivery-delay\u0026gt;0\u0026lt;/redelivery-delay\u0026gt; \u0026lt;!-- with -1 only the global-max-size is in use for limiting --\u0026gt; \u0026lt;max-size-bytes\u0026gt;-1\u0026lt;/max-size-bytes\u0026gt; \u0026lt;message-counter-history-day-limit\u0026gt;10\u0026lt;/message-counter-history-day-limit\u0026gt; \u0026lt;address-full-policy\u0026gt;PAGE\u0026lt;/address-full-policy\u0026gt; \u0026lt;auto-create-queues\u0026gt;true\u0026lt;/auto-create-queues\u0026gt; \u0026lt;auto-create-addresses\u0026gt;true\u0026lt;/auto-create-addresses\u0026gt; \u0026lt;auto-create-jms-queues\u0026gt;true\u0026lt;/auto-create-jms-queues\u0026gt; \u0026lt;auto-create-jms-topics\u0026gt;true\u0026lt;/auto-create-jms-topics\u0026gt; \u0026lt;/address-setting\u0026gt; \u0026lt;!--default for catch all--\u0026gt; \u0026lt;address-setting match=\u0026#34;#\u0026#34;\u0026gt; \u0026lt;dead-letter-address\u0026gt;DLQ\u0026lt;/dead-letter-address\u0026gt; \u0026lt;expiry-address\u0026gt;ExpiryQueue\u0026lt;/expiry-address\u0026gt; \u0026lt;redelivery-delay\u0026gt;0\u0026lt;/redelivery-delay\u0026gt; \u0026lt;!-- with -1 only the global-max-size is in use for limiting --\u0026gt; \u0026lt;max-size-bytes\u0026gt;-1\u0026lt;/max-size-bytes\u0026gt; \u0026lt;message-counter-history-day-limit\u0026gt;10\u0026lt;/message-counter-history-day-limit\u0026gt; \u0026lt;address-full-policy\u0026gt;PAGE\u0026lt;/address-full-policy\u0026gt; \u0026lt;auto-create-queues\u0026gt;true\u0026lt;/auto-create-queues\u0026gt; \u0026lt;auto-create-addresses\u0026gt;true\u0026lt;/auto-create-addresses\u0026gt; \u0026lt;auto-create-jms-queues\u0026gt;true\u0026lt;/auto-create-jms-queues\u0026gt; \u0026lt;auto-create-jms-topics\u0026gt;true\u0026lt;/auto-create-jms-topics\u0026gt; \u0026lt;/address-setting\u0026gt; \u0026lt;/address-settings\u0026gt; \u0026lt;addresses\u0026gt; \u0026lt;address name=\u0026#34;DLQ\u0026#34;\u0026gt; \u0026lt;anycast\u0026gt; \u0026lt;queue name=\u0026#34;DLQ\u0026#34;/\u0026gt; \u0026lt;/anycast\u0026gt; \u0026lt;/address\u0026gt; \u0026lt;address name=\u0026#34;ExpiryAddress\u0026#34;\u0026gt; \u0026lt;anycast\u0026gt; \u0026lt;queue name=\u0026#34;ExpiryQueue\u0026#34;/\u0026gt; \u0026lt;/anycast\u0026gt; \u0026lt;/address\u0026gt; \u0026lt;address name=\u0026#34;data-inbound\u0026#34;\u0026gt; \u0026lt;anycast\u0026gt; \u0026lt;queue name=\u0026#34;data-inbound\u0026#34;/\u0026gt; \u0026lt;/anycast\u0026gt; \u0026lt;/address\u0026gt; \u0026lt;address name=\u0026#34;data-transformed\u0026#34;\u0026gt; \u0026lt;anycast\u0026gt; \u0026lt;queue name=\u0026#34;data-transformed\u0026#34;/\u0026gt; \u0026lt;/anycast\u0026gt; \u0026lt;/address\u0026gt; \u0026lt;/addresses\u0026gt; \u0026lt;/core\u0026gt; \u0026lt;/configuration\u0026gt; Apply the template for your message broker and OpenShift will rollout a new instance of Artemis ActiveMQ in your namespace. Commit and push your changes, then deploy your microservices with your pipelines again. Check the logs of the data-consumer and you will see that the messaging works like a charm.\n","excerpt":"Let\u0026rsquo;s configure our microservices and message broker on OpenShift so we can test this in our …","ref":"/quarkus-techlab/docs/06.0/deployment/","title":"6.2 To the cloud"},{"body":"7.1 Reactive messaging with Kafka We have defined our requirements for our new microservices which we want to have reactive. Apache Kafka brings a lot of handy features to build such systems at big scale.\nIn this chapter we want to use Apache Kafka as our message oriented middleware. Kafka has some own concepts and introduces a ton of other functionality. But for starters were going to use it as a simple message broker.\n7.1.1: Define Kafka Cluster In this techlab you are going to set up your own Kafka cluster which will handle your messages. Add the following resource definition to your infrastructure project under quarkus-techlab-infrastructure/src/main/openshift/kafka:\napiVersion:kafka.strimzi.io/v1beta1kind:Kafkametadata:name:quarkus-techlab-userspec:kafka:version:2.5.0replicas:1listeners:plain:{}tls:{}config:auto.create.topics.enable:falseoffsets.topic.replication.factor:1transaction.state.log.replication.factor:1transaction.state.log.min.isr:1log.message.format.version:\u0026#34;2.5\u0026#34;storage:type:jbodvolumes:- id:0type:persistent-claimsize:10GideleteClaim:falsezookeeper:replicas:1storage:type:persistent-claimsize:10GideleteClaim:falseentityOperator:topicOperator:{}userOperator:{}For starters we need a simple Kafka Topic manual which we will use as communication channel to transfer data from one microservice to another.\napiVersion:kafka.strimzi.io/v1beta1kind:KafkaTopicmetadata:name:manuallabels:strimzi.io/cluster:quarkus-techlab-userspec:partitions:1replicas:1config:retention.ms:7200000segment.bytes:1073741824If you apply these manifests you can see the Kafka cluster appear in your OpenShift project.\noc apply -f quarkus-techlab-infrastructure/src/main/openshift/kafka You will see that OpenShift will deploy a single node Kafka cluster into your namespace.\nFor local development we will create a small docker-compose file to start a Kafka cluster:\nquarkus-techlab-infrastructure/src/main/docker/kafka/docker-compose.yml\nversion:\u0026#39;2\u0026#39;services:zookeeper:image:strimzi/kafka:0.11.3-kafka-2.1.0command:[\u0026#34;sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;bin/zookeeper-server-start.sh config/zookeeper.properties\u0026#34;]ports:- \u0026#34;2181:2181\u0026#34;environment:LOG_DIR:/tmp/logskafka:image:strimzi/kafka:0.11.3-kafka-2.1.0command:[\u0026#34;sh\u0026#34;,\u0026#34;-c\u0026#34;,\u0026#34;bin/kafka-server-start.sh config/server.properties --override listeners=$${KAFKA_LISTENERS} --override advertised.listeners=$${KAFKA_ADVERTISED_LISTENERS} --override zookeeper.connect=$${KAFKA_ZOOKEEPER_CONNECT}\u0026#34;]depends_on:- zookeeperports:- \u0026#34;9092:9092\u0026#34;environment:LOG_DIR:\u0026#34;/tmp/logs\u0026#34;KAFKA_ADVERTISED_LISTENERS:PLAINTEXT://localhost:9092KAFKA_LISTENERS:PLAINTEXT://0.0.0.0:9092KAFKA_ZOOKEEPER_CONNECT:zookeeper:2181Start your cluster with:\ndocker-compose -f quarkus-techlab-infrastructure/src/main/docker/kafka/docker-compose.yml up -d 7.1.2: Producing messages In order to use reactive messaging with kafka in our microservices we will add another extension to them:\n./quarkus-techlab-data-producer/mvnw quarkus:add-extension -Dextensions=\u0026#34;smallrye-reactive-messaging-kafka\u0026#34; ./quarkus-techlab-data-consumer/mvnw quarkus:add-extension -Dextensions=\u0026#34;smallrye-reactive-messaging-kafka\u0026#34; Let\u0026rsquo;s start by creating a reactive producer which is going to do the same thing he always does: Produce random SensorMeasurements.\n// ch.puzzle.quarkustechlab.reactiveproducer.boundary.ReactiveDataProducer.java  @ApplicationScoped public class ReactiveDataProducer { @Outgoing(\u0026#34;data-inbound-reactive\u0026#34;) public Flowable\u0026lt;SensorMeasurement\u0026gt; generateStream() { return Flowable.interval(5, TimeUnit.SECONDS) .map(tick -\u0026gt; new SensorMeasurement()); } } As you can see we create a Flowable of SensorMeasurement which you can imagine as a stream of data sent to the channel \u0026ldquo;data-inbound-reactive\u0026rdquo;. After setting up the data producer we need to connect the Connectors to our Kafka cluster.\n#application.properties[...]# Configure the SmallRye Kafka connectorkafka.bootstrap.servers=quarkus-techlab-kafka-bootstrap:9092%dev.kafka.bootstrap.servers=localhost:9092# Configure the Kafka sinkmp.messaging.outgoing.data-inbound-reactive.connector=smallrye-kafkamp.messaging.outgoing.data-inbound-reactive.topic=manualmp.messaging.outgoing.data-inbound-reactive.value.serializer=io.quarkus.kafka.client.serialization.JsonbSerializer7.1.3: Consuming messages On the other side we want to consume the data we just produced in the Kafka manual Topic. Let\u0026rsquo;s create a ReactiveDataConsumer class:\n// ch.puzzle.quarkustechlab.reactiveconsumer.boundary.ReactiveDataConsumer.java  @ApplicationScoped public class ReactiveDataConsumer { private final Logger logger = Logger.getLogger(ReactiveDataConsumer.class.getName()); @Incoming(\u0026#34;data\u0026#34;) public void consumeStream(SensorMeasurement sensorMeasurement) { logger.info(\u0026#34;Received reactive message: \u0026#34; + JsonbBuilder.create().toJson(sensorMeasurement)); } } To receive and deserialize our messages we need to impelement a SensorMeasurementDeserializer which inherits from the JsonbDeserializer:\n// ch.puzzle.quarkustechlab.reactiveconsumer.control.SensorMeasurementDeserializer  public class SensorMeasurementDeserializer extends JsonbDeserializer\u0026lt;SensorMeasurement\u0026gt; { public SensorMeasurementDeserializer() { super(SensorMeasurement.class); } } After creating the deserializer we need to setup the connectors for the consumer to connect to our Kafka cluster:\n[...]# Configure the SmallRye Kafka connectorkafka.bootstrap.servers=quarkus-techlab-kafka-bootstrap:9092%dev.kafka.bootstrap.servers=localhost:9092# Configure the Kafka sinkmp.messaging.incoming.data.connector=smallrye-kafkamp.messaging.incoming.data.topic=manualmp.messaging.incoming.data.value.deserializer=ch.puzzle.quarkustechlab.reactiveconsumer.control.SensorMeasurementDeserializerWhen you are finished, test your applications first locally. If they work and deliver the desired output, commit your changes, push them and release them with your pipelines!\n","excerpt":"7.1 Reactive messaging with Kafka We have defined our requirements for our new microservices which …","ref":"/quarkus-techlab/docs/07.0/kafka/","title":"7.1 Reactive messaging with Kafka"},{"body":"8.1.1: Jaeger ","excerpt":"8.1.1: Jaeger ","ref":"/quarkus-techlab/docs/08.0/jaeger/","title":"8.1 Tracing powered by Jaeger"},{"body":"Task 2.1.1: Create your application To create your first Quarkus application you have several possibilities:\n Create your application with the Quickstart UI Create your application with maven  To create your application with maven you can execute the following maven command:\nmvn io.quarkus:quarkus-maven-plugin:1.7.0.Final:create \\  -DprojectGroupId=ch.puzzle \\  -DprojectArtifactId=getting-started \\  -DclassName=\u0026#34;ch.puzzle.quarkustechlab.GreetingResource\u0026#34; \\  -Dpath=\u0026#34;/hello\u0026#34; Which creates a generated getting-started application bootstrapped for you. The application holds at the moment a rest resource called GreetingResource.java which exposes a REST resource for you. To test the application you can start the application in dev-mode by executing\n./mvnw compile quarkus:dev The command starts the application in dev-mode which means you do have active live reloading on each API call. Try hitting the API and test the GreetingResource.java:\ncurl http://localhost:8080/hello You should get the \u0026lsquo;hello\u0026rsquo; response in your console. Try altering the response given in the GreetingResource.java and hit the API again, Quarkus should perform a live reload and print the altered response without manually restarting your application.\nOther RESTeasy functionalities work like they always do. For further information on basic REST interaction with Quarkus see Documentation.\n","excerpt":"Task 2.1.1: Create your application To create your first Quarkus application you have several …","ref":"/quarkus-techlab/docs/02.0/first-application/","title":"2.1 Your first Quarkus application"},{"body":"2.2.1: Implementing REST Services In this section we learn how microservices can communicate through REST. In this example we want to build a microservice which produces random data when it\u0026rsquo;s REST interface is called. Another microservice consumes then the data and exposes it on ot\u0026rsquo;s own endpoint.\n2.2.2: Producing Data Create a new Quarkus application like shown before called \u0026lsquo;data-producer\u0026rsquo;. The application should expose a DataResource on the path \u0026ldquo;/data\u0026rdquo; which provides the user with a randomly generated double when requested.\nmvn io.quarkus:quarkus-maven-plugin:1.7.0.Final:create \\  -DprojectGroupId=ch.puzzle \\  -DprojectArtifactId=data-producer \\  -DclassName=\u0026#34;ch.puzzle.quarkustechlab.restproducer.boundary.DataResource\u0026#34; \\  -Dpath=\u0026#34;/data\u0026#34; To write better APIs and share data over our defined resources, we need the \u0026lsquo;resteasy-jsonb\u0026rsquo; extension which provides us with JSON-B functionalities for our REST interfaces. To add an extension to your existing Quarkus application simply use:\n./mvnw quarkus:add-extension -Dextensions=\u0026#34;quarkus-resteasy-jsonb\u0026#34; To see the available extensions you can use:\n./mvnw quarkus:list-extensions You are also able to just add the new dependency to your pom.yml manually.\nIn the generated DataResource edit the @GET endpoint to return a simple double and change the @Produces type to MediaType.APPLICATION_JSON.\n@GET @Produces(MediaType.APPLICATION_JSON) public double produceData() { return Math.random() * 10; } In our lab we want to transfer sensor measurements between our microservices. Create a new class SensorMeasurement with a single public field called data which holds a Double. In the constructor assign the data field a random generated Double. Edit your REST resource to return a new SensorMeasurement whenever it\u0026rsquo;s called.\nIt should look something like this:\npublic class SensorMeasurement { public Double data; public SensorMeasurement() { this.data = Math.random(); } } @Path(\u0026#34;/data\u0026#34;) public class DataResource { @GET @Produces(MediaType.APPLICATION_JSON) public SensorMeasurement produceData() { return new SensorMeasurement(); } } Please update or delete the generated tests which Quarkus provides when generating a project. They will not be needed any further and only have demonstration purposes.\nFor more information about writing REST APIs with Quarkus see the documentation\n2.2.3: Consuming Data With another microservice we would like to consume the data served by our data-producer. Create another quarkus application called \u0026lsquo;data-consumer\u0026rsquo; with the follwing extensions: \u0026ldquo;rest-client, resteasy-jsonb\u0026rdquo;.\nmvn io.quarkus:quarkus-maven-plugin:1.7.0.Final:create \\  -DprojectGroupId=ch.puzzle \\  -DprojectArtifactId=data-consumer \\  -DclassName=\u0026#34;ch.puzzle.quarkustechlab.restconsumer.boundary.DataConsumer\u0026#34; \\  -Dpath=\u0026#34;/data\u0026#34; \\  -Dextensions=\u0026#34;rest-client, resteasy-jsonb\u0026#34; In the data-consumer microservice we will have another resource on the path \u0026ldquo;/data\u0026rdquo; which serves for now as a proxy to our data-producer. We will consume the data-producer microservices API with a service called DataProducerService. To achieve that, generate an interface called DataProducerService which mirrors the data-producer\u0026rsquo;s DataResource. Annotate the DataProducerService with the MicroProfile annotation @RegisterRestClient to allow Quarkus to acces the interface for CDI Injection as a REST Client.\n// DataProducerService  @Path(\u0026#34;/data\u0026#34;) @RegisterRestClient public interface DataProducerService { @GET @Produces(\u0026#34;application/json\u0026#34;) SensorMeasurement getSensorMeasurement(); } Implement the same POJO as in the producer again for the data-consumer project.\nTo access the defined interface as a RestClient we need to configure it properly. To configure the rest client we can edit our application.properties. We need to define at least the base url which the RestClient should use and the default injection scope for the CDI bean.\nch.puzzle.quarkustechlab.restconsumer.boundary.DataProducerService/mp-rest/url=http://localhost:8080ch.puzzle.quarkustechlab.restconsumer.boundary.DataProducerService/mp-rest/scope=javax.inject.SingletonWhen managing multiple RestClients the configuration with the fully qualified name of the class (ch.puzzle.quarkustechlab.restconsumer.boundary.DataProducerService) the readability suffers pretty fast. You can extend the annotation of the RestClient (@RegisterRestClient) with a configKey property to shorten the configurations.\n// DataProducerService  [...] @Path(\u0026#34;/data\u0026#34;) @RegisterRestClient(configKey = \u0026#34;data-producer-api\u0026#34;) public interface DataProducerService { [...] // application.properties data-producer-api/mp-rest/url=http://localhost:8080 data-producer-api/mp-rest/scope=javax.inject.Singleton To use the registered RestClient in our application inject it into the DataConsumerResource and simply call the defined interface\u0026rsquo;s method. To inject a RestClient into your desired class create a field of type DataProducerService dataProducerService and annotate it with @RestClient. You can edit our resource in the data-consumer to use the DataProducerService to create a proxy consuming the data-producer\u0026rsquo;s API and return it.\n@Path(\u0026#34;/data\u0026#34;) public class DataConsumerResource { @RestClient DataProducerService dataProducerService; @GET @Produces(MediaType.APPLICATION_JSON) public SensorMeasurement getData() { return dataProducerService.getSensorMeasurement(); } } To run both microservices you have to alter the application.properties of the consumer and change it\u0026rsquo;s default port. Simply add quarkus.http.port=8081 to your application.properties and the default port will be changed.\nWhen you have both microservices running, try sending a request to the consumer. You will see that we receive a SensorMeasurement, which the data-producer produced.\n","excerpt":"2.2.1: Implementing REST Services In this section we learn how microservices can communicate through …","ref":"/quarkus-techlab/docs/02.0/implementing-rest/","title":"2.2 Impelementing RESTs Services"},{"body":"2.3.1: Fault Tolerance As our application grows in complexity and in horizontal distribution, microservices will get their own lifecycles. We need our application to be more resilient when microservices are temporarily unavailable. In a complex structure where one HTTP request from an entrypoint triggers multiple other REST calls in our distributed system a single error at the end of the call-trace will result in chaotic behaviour if we don\u0026rsquo;t anticipate this early enough.\nThe microprofile \u0026lsquo;fault-tolerance\u0026rsquo; (Quarkus extension: smallrye-fault-tolerance) comes in very handy to implement simple but effective design patterns to be prepared for said events. Add this extension to both of your microservices!\nHint: Maybe it\u0026rsquo;s a good time to tag your repositories for the consumer and producer at this point. We are going to intentionally break some code and test fault tolerance which we will revert after each example.\n2.3.1.1: Resilience through Retries A common approach to gain resilience in our system is to add a retry mechanism. With the annotation @Retry we can enable an automated retries whenever the called method throws an RuntimeException.\nLet\u0026rsquo;s take a look at an example:\nIn the data-producer project let\u0026rsquo;s change our REST endpoint, which serves data to the consumer, so it will fail randomly.\n@Path(\u0026#34;/data\u0026#34;) public class DataResource { private static Logger logger = Logger.getLogger(DataResource.class.getName()); Random random = new Random(); @GET @Produces(MediaType.APPLICATION_JSON) public SensorMeasurement getSensorMeasurement() { logger.info(\u0026#34;getSensorMeasurement called!\u0026#34;); if (random.nextBoolean()) { logger.severe(\u0026#34;Failed!\u0026#34;); throw new RuntimeException(); } return new SensorMeasurement(); } } As you can see we introduced a random boolean which will make the endpoint to fail half the time. We added a log for you to see that the retries will work and the endpoint will be called multiple times!\nIf we start up both microservices and try to consume data multiple times, we can see that the rest-consumer has trouble to consume data when the producer throws an exception. The default behaviour is just to return the Exception when the endpoint is called. This behaviour is nothing we would like to have in our production ready environment.\nIn our data-consumer project we will add the retry mechanism. Add the extension smallrye-fault-tolerance if you don\u0026rsquo;t already have and edit our DataProducerService interface:\n@Path(\u0026#34;/data\u0026#34;) @RegisterRestClient(configKey = \u0026#34;data-producer-api\u0026#34;) public interface DataProducerService { @GET @Produces(\u0026#34;application/json\u0026#34;) @Retry(maxRetries = 10) SensorMeasurement getSensorMeasurement(); } You can see that we added the @Retry annotation and configured it to have a maximum of retries before it fails. Let\u0026rsquo;s try to consume data again. If you send a request to your data-consumer you can see now from the amount of logs produced by the data-producer that after a failure the endpoint is instantaniously called again.\n2.3.1.2: Timeouts The @Timeout annotation can be used to mark functions which will have a finite amount of time before a TimeoutException will be thrown.\nWe update our producer to take a random amount of time to answer with the desired response.\n@Path(\u0026#34;/data\u0026#34;) public class DataResource { private static Logger logger = Logger.getLogger(DataResource.class.getName()); Random random = new Random(); @GET @Produces(MediaType.APPLICATION_JSON) public SensorMeasurement getSensorMeasurement() throws InterruptedException { logger.info(\u0026#34;getSensorMeasurement called!\u0026#34;); Thread.sleep(random.nextInt(1000)); return new SensorMeasurement(); } } Then update the DataProducerService of our data-consumer to time out after 500ms:\n@Path(\u0026#34;/data\u0026#34;) @RegisterRestClient(configKey = \u0026#34;data-producer-api\u0026#34;) public interface DataProducerService { @GET @Produces(\u0026#34;application/json\u0026#34;) @Timeout(500) SensorMeasurement getSensorMeasurement(); } If you send a request to the consumer, you will see that about half of the time we will run into a TimeoutException. The method took longer than 500 ms to finish, so the @Timeout(500) interrupted the invocation.\n2.3.1.3: Fallbacks When we insert timeouts or a maximum amount of retries for a certain part of our code, we want to handle these exceptional states. We can use the @Fallback annotation to define a fallback for the failing method. We can annotate a function with @Fallback(fallbackMethod = \u0026quot;defaultMethod\u0026quot;) so when the annotated method fails, the defined fallback method defaultMethod() will be invoked instead.\nLet\u0026rsquo;s update the example from before to use a fallback if it takes longer than the defined 500 ms to respond:\n@Path(\u0026#34;/data\u0026#34;) @RegisterRestClient(configKey = \u0026#34;data-producer-api\u0026#34;) public interface DataProducerService { @GET @Produces(\u0026#34;application/json\u0026#34;) @Timeout(500) @Fallback(fallbackMethod = \u0026#34;getDefaultMeasurement\u0026#34;) SensorMeasurement getSensorMeasurement(); default SensorMeasurement getDefaultMeasurement() { return new SensorMeasurement(); } } We have seen that we can increase resilience in our microservices without touching the business logic at all. You can try to make your application more fault tolerant and commit your changes whenever you\u0026rsquo;re ready to move on!\n","excerpt":"2.3.1: Fault Tolerance As our application grows in complexity and in horizontal distribution, …","ref":"/quarkus-techlab/docs/02.0/fault-tolerance/","title":"2.3 REST Fault Tolerance"},{"body":"","excerpt":"","ref":"/quarkus-techlab/about/","title":"About"},{"body":"","excerpt":"","ref":"/quarkus-techlab/docs/","title":"Docs"},{"body":"  #td-cover-block-0 { background-image: url(/quarkus-techlab/featured-background_huf8b1504ff0064534a5a83c58fec4a04e_1559845_960x540_fill_q75_catmullrom_top.jpg); } @media only screen and (min-width: 1200px) { #td-cover-block-0 { background-image: url(/quarkus-techlab/featured-background_huf8b1504ff0064534a5a83c58fec4a04e_1559845_1920x1080_fill_q75_catmullrom_top.jpg); } }  Welcome to the Quarkus Techlab Labs   Slides   Show more!\n\n              Slides Get the slides for this training\nRead more …\n   Labs Start with your lab session\nRead more …\n   About Read more …\n    ","excerpt":"#td-cover-block-0 { background-image: …","ref":"/quarkus-techlab/","title":"Quarkus Techlab"}]